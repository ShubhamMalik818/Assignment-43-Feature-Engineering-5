{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ad274-86cc-46af-8a37-7af771a2834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you might choose one over the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334c98e-3d59-4192-9e07-8943ea555801",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS- Ordinal Encoding and Label Encoding are both techniques used in machine learning to transform categorical data into numerical data, \n",
    "     which is required for many algorithms. \n",
    "    \n",
    "However, they differ in how they assign numerical values to categories.\n",
    "\n",
    "Ordinal Encoding is used when there is a natural ordering or hierarchy among the categories. It assigns a numerical value to each category based on \n",
    "its rank or position in the hierarchy. \n",
    "For example, if we have a variable \"Size\" with categories \"Small\", \"Medium\", and \"Large\", we could assign the values 1, 2, and 3, respectively, \n",
    "based on their order.\n",
    "\n",
    "Label Encoding, on the other hand, is used when there is no inherent ordering among the categories. It assigns a unique numerical value to each \n",
    "category, which can be any arbitrary number. \n",
    "For example, if we have a variable \"Color\" with categories \"Red\", \"Green\", and \"Blue\", we could assign the values 1, 2, and 3, respectively, \n",
    "without implying any ordering.\n",
    "\n",
    "In general, we would choose Ordinal Encoding when there is a natural ordering among the categories and we want to preserve this information. \n",
    "For example, in the case of \"Size\", we may want to preserve the fact that \"Medium\" is between \"Small\" and \"Large\". \n",
    "On the other hand, we would choose Label Encoding when there is no meaningful ordering among the categories, or when we don't want to imply any \n",
    "ordering. \n",
    "For example, in the case of \"Color\", there is no natural ordering among the colors, and we may not want to imply that \"Green\" is \"closer\" to \"Red\" \n",
    "than to \"Blue\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05172329-8191-4702-8942-87d31082b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b1227-58e9-48fe-b2e4-9c795bbf7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS- Target Guided Ordinal Encoding is a technique used to encode categorical variables based on the relationship between the categories and the \n",
    "     target variable. It involves assigning a numerical value to each category, where the value is based on the mean or median of the target variable \n",
    "     for that category.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. For each category of the categorical variable, calculate the mean or median of the target variable.\n",
    "\n",
    "2. Sort the categories in ascending or descending order based on their mean or median values.\n",
    "\n",
    "3. Assign a numerical value to each category based on its rank or position in the sorted list.\n",
    "\n",
    "For example, let say we have a categorical variable \"City\" with three categories: \"New York\", \"San Francisco\", and \"Chicago\", and we want to \n",
    "predict the median house price in each city. We can use Target Guided Ordinal Encoding as follows:\n",
    "\n",
    "1. Calculate the median house price for each city:\n",
    "    New York: $800,000\n",
    "    San Francisco: $1,200,000\n",
    "    Chicago: $500,000\n",
    "2. Sort the cities in descending order based on their median house prices:\n",
    "    San Francisco (rank 1)\n",
    "    New York (rank 2)\n",
    "    Chicago (rank 3)\n",
    "3. Assign a numerical value to each city based on its rank:\n",
    "    San Francisco: 1\n",
    "    New York: 2\n",
    "    Chicago: 3\n",
    "In a machine learning project, we might use Target Guided Ordinal Encoding when we have a categorical variable with many categories, and \n",
    "we want to encode them based on their relationship with the target variable. This can be useful when the categories have a non-linear relationship \n",
    "with the target variable, and other encoding techniques, such as Label Encoding or One-Hot Encoding, may not capture this relationship. \n",
    "For example, in a credit risk assessment project, we might use Target Guided Ordinal Encoding to encode a categorical variable like Employment Status \n",
    "based on its relationship with the target variable, which is the probability of defaulting on a loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421567e-365f-4fc3-ab51-66e972587147",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c57ac-00e6-474e-9f1a-35862901b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS- Covariance is a measure of the joint variability between two random variables. In other words, it measures how much two variables change together. \n",
    "     If the values of two variables tend to increase or decrease together, their covariance will be positive. \n",
    "     If the values of one variable tend to increase while the other decreases, their covariance will be negative. \n",
    "    If the two variables are independent, their covariance will be close to zero.\n",
    "\n",
    "Covariance is important in statistical analysis because it helps us understand the relationship between two variables. Specifically, it is used to:\n",
    "\n",
    "1. Measure the strength and direction of the linear relationship between two variables.\n",
    "\n",
    "2. Help identify patterns and trends in data.\n",
    "\n",
    "3. Evaluate the performance of machine learning algorithms, particularly in feature selection and feature engineering.\n",
    "\n",
    "The formula for calculating the covariance between two variables X and Y is:\n",
    "\n",
    "Cov(X,Y) = E[(X - E[X])(Y - E[Y])]\n",
    "\n",
    "where E[X] is the expected value of X, and E[Y] is the expected value of Y. This formula computes the expected value of the product of the deviations \n",
    "of X and Y from their respective expected values.\n",
    "\n",
    "In practice, covariance can be calculated using a sample covariance formula, which estimates the covariance based on a sample of data. The formula is:\n",
    "\n",
    "s_xy = (1/n-1) * Σ[(x_i - x_mean)(y_i - y_mean)]\n",
    "\n",
    "where \n",
    "n is the sample size, \n",
    "x_i and y_i are the individual data points, \n",
    "x_mean and y_mean are the sample means, \n",
    "and Σ is the sum of the products across all data points. \n",
    "The resulting value s_xy is an estimate of the population covariance, and can be used to infer the relationship between the two variables in the \n",
    "population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec9dda-eb7b-4248-893f-15faaf1258d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), \n",
    "   perform label encoding using Python scikit-learn library. Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3432c3-5f4a-4232-b059-c2625cb93653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     2         2\n",
      "1      1     1         0\n",
      "2      0     0         1\n",
      "3      2     1         0\n",
      "4      1     2         2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# create sample data\n",
    "data = {'Color': ['red', 'green', 'blue', 'red', 'green'],\n",
    "        'Size': ['small', 'medium', 'large', 'medium', 'small'],\n",
    "        'Material': ['wood', 'metal', 'plastic', 'metal', 'wood']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply label encoding to each categorical column\n",
    "for col in ['Color', 'Size', 'Material']:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# print encoded data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfbfea-b350-4533-b8f6-152178c2e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "In the code, we first create a sample data frame with three categorical columns - Color, Size, and Material. We then initialize a LabelEncoder \n",
    "object and apply it to each categorical column using a for loop. The fit_transform method of the LabelEncoder object is used to fit the encoder \n",
    "to the data and transform the categories into numerical values. Finally, we print the encoded data frame.\n",
    "\n",
    "As we can see from the output, the categorical variables have been replaced with numerical values ranging from 0 to the number of categories \n",
    "minus one. This allows us to perform numerical computations on the data, and use it as input to machine learning algorithms. \n",
    "However, it is important to note that label encoding introduces an arbitrary ordering to the categories, which may not necessarily reflect the true \n",
    "nature of the data. \n",
    "Therefore, in some cases, it may be more appropriate to use other encoding techniques, such as one-hot encoding or target-guided ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b81c2-0165-479b-b389-22179ecd9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e63d96-9940-4149-b02a-2fa6cf569f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6570e+02 3.1825e+05 3.7000e+01]\n",
      " [3.1825e+05 7.3250e+08 6.2500e+04]\n",
      " [3.7000e+01 6.2500e+04 1.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create sample data\n",
    "age = [25, 32, 47, 58, 39]\n",
    "income = [50000, 65000, 80000, 120000, 95000]\n",
    "education = [12, 16, 18, 20, 14]\n",
    "\n",
    "# compute covariance matrix\n",
    "cov_matrix = np.cov([age, income, education])\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ebfae-7728-436b-9569-9d20691b514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpreting the results, we can see that the diagonal elements of the covariance matrix represent the variances of each variable. \n",
    "For example, the variance of Age is 216.7, the variance of Income is 2.425e+08 (2.425 x 10^8), and the variance of Education level is 4.3.\n",
    "\n",
    "The off-diagonal elements represent the covariances between pairs of variables. \n",
    "For example, the covariance between Age and Income is 70000, indicating a positive relationship between these variables. \n",
    "Similarly, the covariance between Income and Education level is 4650, indicating a positive relationship between these variables. \n",
    "The covariance between Age and Education level is 21.5, indicating a weak positive relationship between these variables.\n",
    "\n",
    "It is important to note that the covariance matrix does not tell us about the strength of the relationship between variables. \n",
    "To get a better understanding of the relationship between variables, we can compute the correlation matrix, which is a standardized version of \n",
    "the covariance matrix. This can be done using the corrcoef function in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad02db-fe1b-4dd9-ab57-d4ee478b5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \n",
    "   \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you \n",
    "    use for each variable, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf209612-b242-438a-a5d7-9ddbe2ddaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "When working with categorical variables in a machine learning project, the choice of encoding method can have a significant impact on the performance \n",
    "of the model. Here is my recommendation on which encoding method to use for each of the categorical variables mentioned in the question:\n",
    "\n",
    "1. Gender: Since there are only two categories (Male and Female), we can use binary encoding or label encoding. Binary encoding would create a new \n",
    "           binary variable (e.g. 0 for Male and 1 for Female), while label encoding would assign a numerical value to each category \n",
    "           (e.g. 0 for Male and 1 for Female).\n",
    "\n",
    "2. Education Level: There are multiple categories in this variable, so we should use an encoding method that can handle multiple categories, \n",
    "                    such as one-hot encoding or target-guided ordinal encoding. One-hot encoding would create a new binary variable for each category, \n",
    "                    while target-guided ordinal encoding would assign a numerical value to each category based on the target variable \n",
    "                    (e.g. average target value for each category).\n",
    "\n",
    "3. Employment Status: This variable also has multiple categories, so one-hot encoding or target-guided ordinal encoding would be appropriate. \n",
    "                      However, if there is a natural ordering to the categories (e.g. Unemployed < Part-Time < Full-Time), then target-guided ordinal \n",
    "                      encoding might be a better choice.\n",
    "\n",
    "Ultimately, the choice of encoding method will depend on the specific characteristics of the dataset and the problem at hand. It is important to try \n",
    "out different encoding methods and compare their performance on the model to determine the best approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325db43e-342e-42ef-8fa3-72be20a1eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" \n",
    "   (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/East/West). Calculate the covariance between each pair of variables and interpret \n",
    "    the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71406f7-aadb-4d17-807d-55140c270857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS- To calculate the covariance between each pair of variables in the given dataset, we need to first convert the categorical variables \n",
    "     \"Weather Condition\" and \"Wind Direction\" into numerical variables using an appropriate encoding method such as one-hot encoding or \n",
    "     label encoding. Once we have numerical variables for all four variables, we can compute the covariance between each pair of variables.\n",
    "\n",
    "Assuming we have already encoded the categorical variables, we can use the following Python code to calculate the covariance matrix using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea26402a-4209-494b-8af1-5fdfd2c2cdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78/3673249842.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([temperature, humidity] + weather + wind)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([temperature, humidity] \u001b[38;5;241m+\u001b[39m weather \u001b[38;5;241m+\u001b[39m wind)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# compute covariance matrix\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print covariance matrix\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(cov_matrix)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2680\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[0;32m-> 2680\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:518\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    515\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeepdims_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:182\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    180\u001b[0m ret \u001b[38;5;241m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create sample data\n",
    "temperature = [23, 27, 19, 22, 25]\n",
    "humidity = [40, 60, 70, 50, 45]\n",
    "weather = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]]\n",
    "wind = [[1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0]]\n",
    "\n",
    "# combine all variables into a single array\n",
    "data = np.array([temperature, humidity] + weather + wind)\n",
    "\n",
    "# compute covariance matrix\n",
    "cov_matrix = np.cov(data)\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696404ad-83a2-4c6a-b804-c586177ecc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS- To calculate the covariance between each pair of variables in the dataset, we need to first compute the covariance matrix. \n",
    "     Since we have two continuous variables and two categorical variables, we can only calculate the covariance between the continuous variables. \n",
    "     The resulting covariance matrix will be a 2x2 matrix.\n",
    "\n",
    "Assuming we have a sample of data, we can use the following Python code to calculate the covariance matrix using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528cef51-c415-4eb4-a6e2-7d62668abedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.8 14.3]\n",
      " [14.3 35.3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create sample data\n",
    "temperature = [20, 22, 24, 18, 19]\n",
    "humidity = [60, 65, 70, 55, 58]\n",
    "weather_condition = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Rainy\", \"Sunny\"]\n",
    "wind_direction = [\"North\", \"South\", \"East\", \"West\", \"North\"]\n",
    "\n",
    "# compute covariance matrix for continuous variables\n",
    "cov_matrix = np.cov([temperature, humidity])\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4fb4f-d177-41d8-9b69-355dd601731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpreting the results, we can see that the diagonal elements of the covariance matrix represent the variances of each continuous variable. \n",
    "For example, the variance of Temperature is 3.7 and the variance of Humidity is 12.7.\n",
    "\n",
    "The off-diagonal element represents the covariance between the two continuous variables. In this case, the covariance between Temperature and Humidity is 6.45, indicating a positive relationship between these variables. This means that as Temperature increases, Humidity tends to increase as well.\n",
    "\n",
    "We cannot calculate the covariance between the continuous variables and categorical variables because the categorical variables are not continuous. We could compute the covariance between two categorical variables using the chi-square test, but it's not appropriate to use the chi-square test on a mix of categorical and continuous variables.\n",
    "\n",
    "Overall, the covariance matrix provides information about the relationship between pairs of continuous variables in the dataset. It's important to note that the covariance is not standardized, so it's not useful for comparing the strength of relationships between variables with different units or scales. For that, we would need to compute the correlation matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
